---
title: Chunk Management
description: Efficient handling of file chunks during upload process.
---

# Chunk Management

The TusFlow API implements efficient chunk management for handling large file uploads.

## Overview

Chunk management enables:

- Reliable large file uploads
- Efficient memory usage
- Parallel upload support
- Upload resumption

## Configuration

```typescript
CHUNK_CONFIG = {
    SIZE: {
        MIN: 5 * 1024 * 1024, // 5MB minimum
        MAX: 50 * 1024 * 1024, // 50MB maximum
        TARGET_UPLOAD_TIME: 1, // Target time in seconds
    },
    STORAGE: {
        TEMP_DIR: './temp',
        CLEANUP_INTERVAL: 3600, // 1 hour
        MAX_AGE: 24 * 3600, // 24 hours
    },
    PARALLEL: {
        MAX_CONCURRENT: 3,
        BATCH_SIZE: 5,
    },
};
```

## Implementation Details

### Chunk Processing

```typescript
async function processChunk(
    chunk: Blob,
    offset: number,
    uploadId: string
): Promise<void> {
    // Validate chunk
    await validateChunk(chunk, offset);

    // Store chunk
    const chunkId = generateChunkId(uploadId, offset);
    await storeChunk(chunkId, chunk);

    // Update upload metadata
    await updateUploadProgress(uploadId, offset + chunk.size);
}
```

### Chunk Assembly

```typescript
async function assembleChunks(
    uploadId: string,
    totalSize: number
): Promise<void> {
    const chunks = await getUploadChunks(uploadId);

    // Verify all chunks are present
    verifyChunks(chunks, totalSize);

    // Combine chunks and upload to final storage
    await combineAndStore(chunks, uploadId);

    // Cleanup temporary chunks
    await cleanupChunks(uploadId);
}
```

## Features

### Dynamic Chunk Sizing

The API adjusts chunk sizes based on:

- Network conditions
- Server load
- Client capabilities

```typescript
function calculateOptimalChunkSize(
    uploadSpeed: number,
    targetTime: number
): number {
    const optimalSize = uploadSpeed * targetTime;
    return Math.min(
        Math.max(optimalSize, CHUNK_CONFIG.SIZE.MIN),
        CHUNK_CONFIG.SIZE.MAX
    );
}
```

### Parallel Uploads

Support for concurrent chunk uploads:

```typescript
async function uploadChunksInParallel(
    file: File,
    uploadId: string
): Promise<void> {
    const chunks = splitFileIntoChunks(file);
    const batches = createChunkBatches(
        chunks,
        CHUNK_CONFIG.PARALLEL.BATCH_SIZE
    );

    for (const batch of batches) {
        await Promise.all(batch.map((chunk) => uploadChunk(chunk, uploadId)));
    }
}
```

### Cleanup Process

Automatic cleanup of temporary chunks:

```typescript
async function cleanupExpiredChunks(): Promise<void> {
    const expiredChunks = await findExpiredChunks(CHUNK_CONFIG.STORAGE.MAX_AGE);

    for (const chunk of expiredChunks) {
        await deleteChunk(chunk.id);
        await updateUploadStatus(chunk.uploadId, 'expired');
    }
}
```

## Error Handling

The API handles various chunk-related errors:

```typescript
async function handleChunkError(
    error: Error,
    chunk: Blob,
    uploadId: string
): Promise<void> {
    if (error instanceof ChunkValidationError) {
        await invalidateChunk(uploadId, chunk.offset);
        throw new Error('Invalid chunk received');
    }

    if (error instanceof StorageError) {
        await retryChunkStorage(chunk, uploadId);
    }

    // Log error for monitoring
    await logChunkError(error, uploadId);
}
```

## Best Practices

1. **Chunk Size Selection**

    - Consider network conditions
    - Balance memory usage
    - Optimize for client capabilities

2. **Error Recovery**

    - Implement retry logic
    - Handle network failures
    - Maintain chunk integrity

3. **Performance Optimization**

    - Use parallel uploads
    - Implement caching
    - Optimize storage operations

4. **Resource Management**
    - Clean up temporary files
    - Monitor storage usage
    - Handle expired uploads

## Example Usage

Client-side implementation:

```typescript
async function uploadLargeFile(file: File): Promise<void> {
    // Create upload
    const uploadId = await createUpload(file.size);

    // Split file into chunks
    const chunks = splitIntoChunks(file, CHUNK_CONFIG.SIZE.MAX);

    // Upload chunks in parallel
    const uploadTasks = chunks.map(async (chunk, index) => {
        const offset = index * CHUNK_CONFIG.SIZE.MAX;

        try {
            await uploadChunk(chunk, uploadId, offset);
        } catch (error) {
            await handleChunkError(error, chunk, uploadId);
        }
    });

    // Wait for all chunks to upload
    await Promise.all(uploadTasks);

    // Complete upload
    await finalizeUpload(uploadId);
}
```

## Testing

Example chunk management tests:

```typescript
describe('Chunk Management', () => {
    it('should process chunks in order', async () => {
        const file = new File(['content'], 'test.txt');
        const chunks = splitIntoChunks(file, 1024);

        for (const chunk of chunks) {
            await processChunk(chunk, chunk.offset, 'test-upload');
        }

        const result = await assembleChunks('test-upload', file.size);
        expect(result).toBeTruthy();
    });

    it('should handle parallel uploads', async () => {
        const chunks = generateTestChunks(5);
        const results = await Promise.all(
            chunks.map((chunk) => uploadChunk(chunk, 'test-upload'))
        );

        expect(results.every((r) => r.success)).toBe(true);
    });

    it('should clean up expired chunks', async () => {
        const expiredChunk = await createExpiredChunk();
        await cleanupExpiredChunks();

        const exists = await checkChunkExists(expiredChunk.id);
        expect(exists).toBe(false);
    });
});
```
